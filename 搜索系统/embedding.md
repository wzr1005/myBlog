
激活函数的另一个重要的作用是 执行数据的归一化，将输入数据映射到某个范围内，再往下传递，这样做的好处是可以限制数据的扩张，防止数据过大导致的溢出风险。

这里还要提一下：为什么要使用非线性的激活函数？

因为如果使用线性的激活函数，那么输入x跟输出y之间的关系为线性的，便可以不需要网络结构，直接使用线性组合便可以。

只有在输出层极小可能使用线性激活函数，在隐含层都使用非线性激活函数。

![](https://tva1.sinaimg.cn/large/e6c9d24egy1h499iy4hhyj20ep0bbdfu.jpg)

想办法把圆和三角形切开，需要用到相关的激活函数，把他们落到相应的区间。

再传递给下一层。

“loss函数的作用就是描述模型的预测值与真实值之间的差距大小。

keras.layers.Embedding(input_dim, output_dim, input_length)

input_dim：这是文本数据中词汇的取值可能数。例如，如果您的数据是整数编码为0-9之间的值，那么词汇的大小就是10个单词；

output_dim：这是嵌入单词的向量空间的大小。它为每个单词定义了这个层的输出向量的大小。例如，它可能是32或100甚至更大，可以视为具体问题的超参数；

input_length：这是输入序列的长度，就像您为Keras模型的任何输入层所定义的一样，也就是一次输入带有的词汇个数。

例如，如果您的所有输入文档都由1000个字组成，那么input_length就是1000。

