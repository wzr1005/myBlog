
## json工具、
1. 序列化
2. 实体match
3. 

在InnoDB中，增删改都会立刻修改主键or唯一索引，但是不会rebuild全局索引，而是对这些索引增加值(或移除值)。

对于非唯一性索引，InnoDB会进行change buffering操作。将更改排入队列，之后再在后台将其合并到索引中。甚至，为了后续物理更新更加高效，会将变更进行合并。

在MySQL5.1版本，change buffering操作仅仅适用于insert。而在MySQL5.5版本之后，change buffering操作则扩展到update和delete里。

**insert**的过程，先插入一条数据，再把数据插入到索引当中，如果这个表有五个索引，就要维护这五个索引。

数据插入索引的过程中，先查找在B+树中在不在，能查到的话插入到后面空闲地方，没找到就新增这个值，然后在分支上加入到叶子节点，和指向这个叶子的指针。

在这个过程中，如果一个页满了，一般是4kb，还要申请一个空的页，把满的页拆分开，把一半的索引数据放到空闲页中（扩容重适应操作），

为了保证数据的一致性，会给相关的索引页加上闩（shuan）锁，电路级别的锁



## 遇到比较难的问题是什么？

我的项目需要100万条记录，序列化成json、写成一些对象分别写到数据库、和es集群中，

一开始是每写多少条打印一行日志方便检测或者统计之类的，大概就是：

用了两个线程池，一个线程池写数据库，一个线程池写es，

分别扔到消息队列中，

写数据库的时候发现特别慢，而且数据对不上，

开始是觉得单条sql执行的速度不够快，就会造成连接数过多导致mysql服务器承担不了这么多负载。

**就去优化插入sql，调整最大连接数，与线程池的数量，**

关于数据慢的问题，从索引开始查，发现自己建了很多索引，那么我们知道，mysql的索引虽然能够增加查询的速度，但对于增改操作是个负担，

当执行insert操作时，需要先写入一行数据，然后把表建的索引都扫描一遍将数据写入到B+树中。

要是写满了一个内存页，通常为4kb，还需要扩容重新拆分索引，

为了保证数据的一致性，更新索引的时候还需要上一个闩锁，一个更低级别的内存锁。

因此考虑到插入性能的删掉了一些索引，快了很多，但还是觉得不够快，

后来考虑到这个表经常执行的是全量插入和查找的操作，就把索引换成了myisam。

数据库问题解决了。

但是线程同步的问题还是没解决。

我一开始使用的加锁方式是用的synchronized，因为比较流行把，但是毕竟也是重锁，他有一个锁升级的过程，

但这种频繁开启线程插入的方式决定了他很大概率都是重锁，后来又对比了reentrantlock.lock()的性能，发现他们俩的性能是差不多的

后来又用了vector试了下，也不行，

最后用的ConcurrentLinkedDeque高性能队列，基于cas实现的并发锁，适合频繁插入的场景。

最后解决了速度问题，线程同步的问题还没解决，然后就排查问题，最后查到是因为线程池的submit方法提交的是future

有一些线程在执行的过程中出错了，future的话看了下源码，执行的过程线程catch这个异常不会马上打印日志，而是放在finally里面。

这样我的线程池在提交完了任务一直卡在countdownlatch同步那里，不打印错误日志，然后再去找具体的服务。

## 问题2
关于事务
```java
class a {
    int a = 1;
    public void method(){
        Connection conn = aaa ;//获取数据库连接conn.setAutoCommit(false); //开启事务
        try{
//...执行增删改查sql
            conn.commit(); //提交事务
        }catch (Exception e) {
            conn.rollback();//事务回滚
        }finally{
            conn.close();//关闭链接
        };
    }
}
```

事务一直不生效。

原因是事务的方法修饰用的不是public，方法是使用来代理的，而我的方法是static，静态方法是不能被重写的，

我用的是自定义异常类， 继承的父异常exception抛出的异常不是Spring所支持的

@Transaction所在的方法没有被Spring注册
## 代码习惯
先想想哪些可能是公共模块，把他抽离出来，配置文件不要写在代码里面，

yml文件在启动脚本里拉取，不要直接提交到仓库里面

代码命名最好前缀分类，变量和函数尽量有区别，比如类里面的变量可以以下划线开头，函数以英文字母开头

当然一个成熟的团队会有他自己的规范，融入就好了

## 内存泄露的案例
一个新服务上线运行一段时间之后，老是出现堆内存不足，大量出现fullGC，访问量也不是很高。

jmap -dump:live,format=xxxx.hprof 进程号

下载heap Dump分析工具，将dump文件导入到工具中，查看内存数

发现有个对象使用了149MB内存，占总内存的25%，不太正常。

发现hibernate会对不同的sql进行缓存，最多2048条，而有时候sql是很长的，一条达到1kb，

解决方法，限制缓存大小。

## java

### threadlocal
threadlocal其实就是一个线程下的全局变量，这样在调用其他方法的时候就可以避免很多参数的传递。

threadlocal的map里面key使用的是线程的名称，保存了一个Entry结构。

为了避免内存泄露，在线程的生命结束时，要手动的销毁线程所在key的entry。

这种销毁操作可以用aop来实现。

关于threadlocal您是否还有其他问题呢。

### hashmap实现原理
hashmap先说说定义，他是一个基于hash的key value结构，底层是node数组，存的是链表结构。

我们任何对象都可以作为key进行hashcode来计算出一个hash值，作为map顶层数据的槽位，取出它的value

理想情况下，我们每个key都对应一个槽位，以O（1）的时间复杂度直接随机存取到目标value。

但是实际情况下是很有可能起冲突的，冲突的解决方法有很多种，hashmap使用的拉链法，在key冲突之后存储在数组下的链表中

这样我们在取值的时候可以就需要到链表中去遍历，这样我们的时间复杂度在最坏的情况下可能达到On，

所以hashmap在1。8之后引入了红黑树的结构，红黑树是一种矮胖型结构，如果您关于红黑树有问题探讨的话也可以讨论一下

起冲突的时候当链表长度大于8个的时候链表结构会转为红黑树，这样我们在最坏的情况下时间复杂度也可以降到On

map.put过程就是先判断key是否为空，然后hashcode计算出一个hash值以hashmap的size-1取模得到一个槽位， 若为空则hashcode为0，

拿到槽位之后判断有没有冲突，有冲突再用equal方法看看是不是同一个key，来进行覆盖或者插入链表的操作。

hashmap初始容量是16，负载因子达到0。75时会扩容到2的n次方。Node节点记录来key value next

### 集合类

#### list
数组实现，ArrayList，动态扩容，达到原来的1。5倍就扩容，扩容也是复制的方式实现的
链表实现，LinkedList 双向链表，方便插入删除，
还有一种线程安全的 vector，效率比较低。通常线程安全推荐使用concurrentArrayList非阻塞队列。



#### map
HashTable   线程安全，全表锁
HashMap     线程不安全，
TreeMap     红黑树结构
#### set
HashSet     LinkedHashSet 哈希表结构

TreeSet     红黑树结构

### 垃圾回收

#### 标记垃圾的方法

通常有两个，引用计数法和可达性分析

##### 引用计数法
就是根据某个对象有没有被引用来判断是否存活，这种一般不推荐，因为有循环引用的情况，可能会导致内存泄露。

##### 可达性分析
确定根root，递归对引用的对象进行标记，未被引用的就会被清楚。

标记16次以内都是浮动垃圾，放在新生代，如果超过16次还没被回收就会放在老年代

#### 垃圾回收的算法
标记清除，扫描内存区域标记为垃圾的对象进行回收，速度较快，会有内存碎片

标记整理，将标记为垃圾的对象集中放在一块区域，进行回收，避免内存碎片

复制法，开辟两块空间，将垃圾复制到空的那块空间，回收之后再交换区域，回收的速度较快，但是会占用一定的内存，通常都是使用的这个方法，。

#### 引用类型
强引用，通常new的对象就是，不会被回收

软引用，fullgc时内存满了会回收。处理比较大的资源，适合

弱引用，只要fullgc就会被引用，Threadlocal就是弱引用，适合执行完了就不会再用到的

虚引用，任何情况下都有可能被回收，

分代回收，老年代，新生代

老年代空间不足会触发fullgc，新生代空间不足触发minorgc。

fullgc会引用stw卡顿，因为不卡顿的话线程还在引用。将会引发引用错误。

#### 垃圾回收器

##### 串行，

分为新生代和老年代

适合个人电脑，堆内存比较小，、工作线程暂停，直到被回收

对于响应不严苛的情况下，串行性能比并行好
#### 并行垃圾回收，
分为新生代和老年代

#### 并发回收器
CMS G1




