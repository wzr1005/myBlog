---
title: mmall项目探究
date: 2022-03-01 11:06:58
type: "个人生活"
categories:
- 开源项目
  tags:
  thumbnail: https://tva1.sinaimg.cn/large/008i3skNgy1gt14d2z4q0j31900u0tb5.jpg
---

salt是可以自定义的

MD5('123' + '1ck12b13k1jmjxrg1h0129h2lj') = '6c22ef52be70e11b6f3bcf0f672c96ce'

MD5('456' + '1h029kh2lj11jmjxrg13k1c12b') = '7128f587d88d6686974d6ef57c193628'

由于加了 Salt，即便数据库泄露了，但是由于密码都是加了 Salt 之后的散列，坏人们的数据字典已经无法直接匹配，明文密码被破解出来的概率也大大降低。



(1)insert插入的返回值是新增数据的ID。当然，前提是数据库支持自增的ID主键。

(2)如果没有定义自增主键，那么将返回一个特殊的数，至于这个数是什么，在MyBatis里面是这样定义的：Integer.MIN_VALUE + 1001

mybatis返回0或1，0为插入失败

seckill 用存储过程实现业务逻辑

优点：

　　1. 运行速度：对于很简单的sql，[存储过程](https://so.csdn.net/so/search?q=存储过程&spm=1001.2101.3001.7020)没有什么优势。对于复杂的业务逻辑，因为在存储过程创建的时候，数据库已经对其进行了一次解析和优化。存储过程一旦执行，在内存中就会保留一份这个存储过程，这样下次再执行同样的存储过程时，可以从内存中直接调用，所以执行速度会比普通sql快。  
  　　2. 减少网络传输：存储过程直接就在数据库服务器上跑，所有的数据访问都在数据库服务器内部进行，不需要传输数据到其它服务器，所以会减少一定的网络传输。但是在存储过程中没有多次数据交互，那么实际上网络传输量和直接sql是一样的。而且我们的应用服务器通常与数据库是在同一内网，大数据的访问的瓶颈会是硬盘的速度，而不是网速。
  　　3. 可维护性：的存储过程有些时候比程序更容易维护，这是因为可以实时更新DB端的存储过程。 有些bug，直接改存储过程里的业务逻辑，就搞定了。

缺点：

1. SQL本身是一种结构化查询语言，但不是面向对象的的，本质上还是过程化的语言，面对复杂的业务逻辑，过程化的处理会很吃力。同时SQL擅长的是数据查询而非业务逻辑的处理，如果如果把业务逻辑全放在存储过程里面，违背了这一原则。
2. 如果需要对输入存储过程的参数进行更改，或者要更改由其返回的数据，则您仍需要更新程序集中的代码以添加参数、更新调用，等等，这时候估计会比较繁琐了。**可扩展性不太行**
3. 开发调试复杂，由于IDE的问题，存储过程的开发调试要比一般程序困难。出现问题不好定位，debug较为繁琐
4. 没办法应用缓存。虽然有全局临时表之类的方法可以做缓存，但同样加重了数据库的负担。如果缓存并发严重，经常要加锁，那效率实在堪忧。
5.  不支持群集，数据库服务器无法水平扩展，或者数据库的切割（水平或垂直切割）。数据库切割之后，存储过程并不清楚数据存储在哪个数据库中。

什么情况下适合使用：

1. 适当的使用存储过程，能够提高我们SQL查询的性能，
2.  存储过程不应该大规模使用，滥用。
3. 随着众多ORM 的出现，存储过程很多优势已经不明显。 
4. SQL最大的缺点还是SQL语言本身的局限性——SQL本身是一种结构化查询语言，我们不应该用存储过程处理复杂的业务逻辑——让SQL回归它“结构化查询语言”的功用。复杂的业务逻辑，还是交给代码去处理吧。



启动服务

mysql.server start

关闭服务

mysql.server stop

重启服务

mysql.server restart



数据库方式实现幂等性

对于同一笔业务操作，不管调用多少次，得到的结果都是一样的。

以对接支付宝充值为例，如果我们系统对接支付宝充值功能，需要给支付宝提供一个回调接口，回调接口会携带(

out_trade_no 商品订单号，在商场是唯一的

trade_no支付宝交易号 在支付宝中是唯一的)

根据no去查询订单是否处理过，未处理才继续往下执行

开启本地事务，

操作订单业务逻辑

提交本地事务

释放Lock锁

====================================

但是这只适应并发量小的情况，

一台机器中在一个JVM中Lock是有效的，

不过在互联网系统中，多数是采用集群方式部署系统，同一套代码，

服务器上会部署多套，如果支付宝同时发来多个通知经过负载均衡到不同的机器上

就得用分布式锁来做处理

并发量大的场景有可能出现多个线程查询出来的no都一样的情况，造成数据不一致

悲观锁方式，使用update

1. 接收到支付宝支付成功请求
2. 打开本地事务
3. 查询订单信息并加悲观锁
   select * from t_order where order_id = trade_no for update;
4. 判断订单是否已处理
5. 如果订单已处理直接返回，
6. 给本地系统给用户加钱
7. 将订单状态置为成功
8. 提交本地事务

重点在于for update

注意

update t_order set status = 1 where order_id = trade_np where status = 0;

是依靠乐观锁实现的，status=0作为条件去更新，类似java的CAS操作。

执行这条sql的时候，如果有多个线程同时到达这条代码，数据库内部update同一条记录会排队执行，最终会有一条update会执行成功，其他未成功的，update语句响应为0，根据num来决定是回滚还是提交。

# spring boot使用sharding jdbc的配置--读写分离

- 配置的多个数据源交给sharding-jdbc管理，sharding-jdbc创建一个DataSource数据源提供给mybatis使用

- 配置多个数据源，数据源的名称最好要有一定的规则，方便配置分库的计算规则

- 配置数据源规则，即将多个数据源交给sharding-jdbc管理，并且可以设置默认的数据源，当表没有配置分库规则时会使用默认的数据源

- 配置数据源策略和表策略，具体策略需要自己实现

  ```java
  TableRule orderTableRule = TableRule.builder("t_order")
          .actualTables(Arrays.asList("t_order_0", "t_order_1"))
          .tableShardingStrategy(new TableShardingStrategy("order_id", new ModuloTableShardingAlgorithm()))
          .dataSourceRule(dataSourceRule)
          .build();
  ```

绑定表策略，在查询时会使用**主表策略**计算**路由的数据源**，因此需要约定**绑定表策略的表的规则需要一致**，可以一定程度提高效率

分库策略的简单实现，接口：DatabaseShardingAlgorithm

强制使用主库

HintManager hintManager = HintManager.getInstance();

hintManager.setMasterRouteOnly();

该数据源为shardingjdbc对应的数据源,可通过java代码配置,也可通过配置文件配置,此处我们采用yml配置,配置文件下面会给出*

shardingjdbc有四种数据源，需要根据业务注入不同的数据源

**分片策略：**分片键和分片算法配合起来就是一种分片策略,主要分片策略如下:

 1.标准分片策略：对应StandardShardingStrategy,提高对SQL语句中的=,>,<,>=,<=,IN,AND,BETWEEN等分片操作的支持.StandardShardingStrategy只支持单键分片,提供PreciseShardingAlgorithm和RangeShardingAlgorithm两个分片算法。PreciseShardingAlgorithm是必选的，用于处理=和IN的分片。RangeShardingAlgorithm是可选的，用于处理BETWEEN AND, >, <, >=, <=分片，如果不配置RangeShardingAlgorithm，SQL中的BETWEEN AND将按照全库路由处理

 2.复合分片策略：对应ComplexShardingStrategy。复合分片策略。提供对SQL语句中的=, >, <, >=, <=, IN和BETWEEN AND的分片操作支持。ComplexShardingStrategy支持多分片键，由于多分片键之间的关系复杂，因此并未进行过多的封装，而是直接将分片键值组合以及分片操作符透传至分片算法，完全由应用开发者实现，提供最大的灵活度

**行表达式分片策略**

 t_user_$->{u_id % 8} 表示t_user表根据u_id模8，而分成8张表，表名称为t_user_0到t_user_7。

# Hint分片算法

- 分片策略无需配置分片健
- 分片健值也不再从 SQL 中解析，而是由外部指定分片信息，让 SQL 在指定的分库、分表中执行
- 通过 `Hint` API 在外部手动指定分片健或分片库

然后就是配置 hint 分片 sharding-algorithm-name，type：

```properties
# 配置分库策略  主键+分片算法
spring.shardingsphere.rules.sharding.tables.t_order.database-strategy.hint.sharding-algorithm-name=hint-db
spring.shardingsphere.rules.sharding.sharding-algorithms.hint-db.type=HINT_TEST_DB
```

```properties
# 配置分表策略 主键+分片算法
spring.shardingsphere.rules.sharding.tables.t_order.table-strategy.hint.sharding-algorithm-name=hint-table
spring.shardingsphere.rules.sharding.sharding-algorithms.hint-table.type=HINT_TEST_TAB
```

Singletonlist类
这是一个不可变List，且只有一个元素。

我们知道分库分表是针对某些数据量持续大幅增长的表，比如用户表、订单表等，而不是一刀切将全部表都做分片。那么不分片的表和分片的表如何划分，一般有两种解决方案。

- 严格划分功能库，分片的库与不分片的库剥离开，业务代码中按需切换数据源访问
- 默认数据源，以 `Sharding-JDBC` 为例，不给未分片表设置分片规则，它们就不会执行，因为找不到路由规则，如果我们设置一个默认数据源，**在找不到规则时一律访问默认库。**

先创建两个[数据库](https://cloud.tencent.com/solution/database?from=10680) `ds-0`、`ds-1`，两个库中分别建表 `t_order_0`、`t_order_1`、`t_order_2` 、`t_order_item_0`、`t_order_item_1`、`t_order_item_2` 6张表，下边实操看看如何在不同场景下应用 `sharding-jdbc` 的 4种分片策略。

## **标准分片策略**

**使用场景**：SQL 语句中有`>`，`>=`, `<=`，`<`，`=`，`IN` 和 `BETWEEN AND` 操作符，都可以应用此分片策略。

标准分片策略（`StandardShardingStrategy`），它只支持对单个分片健（字段）为依据的分库分表，并提供了两种分片算法 `PreciseShardingAlgorithm`（精准分片）和 `RangeShardingAlgorithm`（范围分片）。

**“一旦我们没配置范围分片算法，而 SQL 中又用到 `BETWEEN AND` 或者 `like`等，那么 SQL 将按全库、表路由的方式逐一执行，查询性能会很差需要特别注意。**

### **1、精准分片算法**

#### **1.1 精准分库算法**

实现自定义精准分库、分表算法的方式大致相同，都要实现 `PreciseShardingAlgorithm` 接口，并重写 `doSharding()` 方法，只是配置稍有不同，而且它只是个空方法，得我们自行处理分库、分表逻辑。**其他分片策略亦如此**。

SELECT * FROM t_order where  order_id = 1 or order_id in （1,2,3）;



=========================================

其次由于用户数量的提升，高并发的数据库请求也会越来越多，单节点数据库的连接数、TPS以及存储容量都存在上限的限制，并发数达到一定量或者数据量超过了单节点存储容量之后，数据库性能会成为整个系统的瓶颈

最后当数据量很大的时候，数据库的备份和迁移都会变得越来越难，时间成本和难度都会随着数据数量的增长而增大。

所以在单节点关系型数据库无法满足互联网的应用场景时，可以采用NoSQL数据库来分担一部分的压力，但是NoSQL并不能完全替代关系型数据库的特性，

为什么nosql没有取代mysql，部分原因源于当今大多数大数据的性质：本质上仍然是事务性的。

这恰恰也是 MySQL 受欢迎的核心：它是最适合广泛数据库从业人员技能的数据库。

对于一般的场景，具有普遍实用性。

Nosql的优点

MongoDB 是非关系型的[数据库](https://cloud.tencent.com/solution/database?from=10680)（NoSQL)，属于文档型数据库，文档数据库就是为了解决关系数据库带来的问题。最大的特点是 no-schema，可以存储和读取任意的数据。

存储的数据格式就是 JSON（或者 BSON）。JSON 格式我们都比较熟悉，比如 Rest API 请求返回的 Response 就是 JSON 格式的。JSON 格式的数据和 XML 个格式的区别是 JSON 更简单，没有那么多的标签来定义字段名。也就是说 JSON 是自描述的。

另外 JSON 格式存进 MongoDB 中后，**即使读取一个 JSON 中不存在的字段也不会导致 SQL 那样的语法错误**。

### 列式存储型

比如 HBase，按照列来存储数据，解决了大数据场景下的 I/O 问题。

关系型数据库按照行来存储数据，所以称作`行式数据库`。按照行来存储有以下优势：

 读一行数据就能读取到多个列，只需要一次磁盘操作就能把多个列的数据读取到内存中。

写一行数据可以对多个列进行写操作，保证了行数据的原子性和一致性。而对列式存储的多列写操作，可能会导致有些列成功，有些失败，产生数据的不一致。

### MongoDB 优点

由于文档数据库具有 no-schema 特性，用起来有以下几个明显的`好处`。

#### 1）新增的字段不会出错。

比如用户表增加一个`昵称`的字段，不需要像关系型数据那样执行更新表结构的语句。我们直接查询这条文档出来就可以看到新增的字段了。

#### （2）查询历史数据不会出错。

上面提到新增了一个昵称字段，但是历史数据中是没有这个字段，如果查询历史数据，则返回的数据中不会有这个字段，虽然查询不会报错，但是取值时，会返回 null。如果业务代码中用到了昵称字段，则需要做兼容性处理。

#### （3）轻松存储复杂数据。

因为是用 JSON 存储，而 JSON 又可以表示复杂的数据结构，比如字段可以存数组，字段可以嵌套字段，而且可以存很多字段。换做 MySQL，则需要设计几张表来存。MongoDB 存数据的结构，特别适合电商这种业务场景，比如两种不同的商品，属性差别就很大，但是用 JSON 存就可以轻松应对。

### MongoDB 缺点

#### （1）目前 4.0 以前不支持多文档事务。

结合 MongoDB 文档模型内嵌数组、文档的支持，目前的单文档事务能满足绝大部分开发者的需求。为了让 MongoDB 能适应更多的应用场景，让开发变得更简单，

MongoDB 4.0 将支持复制集内部跨一或多个集合的多文档事务，保证针对多个文档的更新的原子性。而在未来的 MongoDB 4.2 版本，还会支持分片集群的分布式事务。

MongoDB 的事务接口非常简单，开发者只需要将`需要保证原子性的更新序列`放到一个 session 的 `开始事务` 与`提交事务`之间即可。下面是 Java 使用 MongoDB 事务的示例代码：

循环依赖的问题怎么解决。可以利用Spring的机制

水平拆分通常是业务层无感知的，也不需要对系统架构设计进行调整，所以水平拆分的方式一般优先于垂直拆分，而垂直拆分往往是系统架构设计的初期就应该做好规划。

#### （2） 不支持关联查询。

我们都知道 MySQL 是支持关联查询的，也就是可以执行 Join 操作。比如有两张表：用户表和订单表，订单表中有用户的 id，且性别只存在用户表中。如果想购买了手机的男性用户，用关联查询，一步就能搞定。但是如果用 MongoDB，则需要查两次，先查询订单表中购买手机的用户，再查询这些用户中哪些是男性。

## 二、关系型数据的缺点

> 2.面试官：这个项目为什么不用关系型数据库？关系型数据库有哪些缺点？

### 关系型数据库的不足之处

**（1）存储的是行记录**。

不能存储数组、嵌套字段等格式的数据。

**（2）扩展表结构不方便**。

操作不存在的列会报错，而增加列又需要执行 SQL 语句才行。而且修改时需要特别注意，因为更新表时会长时间`锁表`，这对线上环境可能造成严重影响。

**（3）占用内存高**。

关系型数据库在对大量数据的表进行统计之类的运算时，占用内存会很高，因为它即使只针对某一列进行运算，也会将整行数据从存储设备读入内存。

**（4）**[**全文搜索**](https://cloud.tencent.com/product/es?from=10680)**性能差**

类似于 MySQL 的关系型数据库，只能用 like 进行整表扫描的匹配，效率很低。现如今，有很多场景需要支持模糊匹配，而且必须支持高效查找。比如查询包含关键字的日志信息，又或者是根据某个商品关键字查询商品列表。

针对以上的不足之处，我们这个项目用了两种非关系型的数据存储方案：MongoDB 和 ElasticSearch。

在MySQL 5.6版本以前,只有MyISAM存储引擎支持全文引擎.在5.6版本中,InnoDB加入了对全文索引的支持,但是不支持中文全文索引.在5.7.6版本,MySQL内置了ngram全文解析器,用来支持亚洲语种的分词.

- 给字段添加全文索引 ALTER TABLE articles ADD FULLTEXT INDEX title_body_index (title,body) WITH PARSER ngram;

mysql> SELECT * FROM articles WHERE MATCH (title,body) AGAINST ('精神' IN NATURAL LANGUAGE MODE);
+----+-----------------+-------------------------+
| id | title           | body                    |
+----+-----------------+-------------------------+
|  1 | 弘扬正能量      | 贯彻党的18大精神        |
+----+-----------------+-------------------------+
1 row in set (0.00 sec)

mysql> SELECT * FROM articles WHERE MATCH (title,body) AGAINST ('精神');
+----+-----------------+-------------------------+

| id   | title | body |
| ---- | ----- | ---- |
|      |       |      |
+----+-----------------+-------------------------+
| 1    | 弘扬正能量 | 贯彻党的18大精神 |
| ---- | ---------- | ---------------- |
|      |            |                  |
+----+-----------------+-------------------------+
1 row in set (0.00 sec)
可以看到,搜索结果命中了一条,且在不指定搜索模式的情况下,默认模式为自然语言搜索.

我们项目中用到日志搜索就是利用 ELK。

`Elasticsearch` 就是 `ELK` 中的 `E`。Elasticsearch 就是全文搜索引擎，注意：他是一种 NoSQL 方案，并不是 NoSQL 数据库。

`Logstash` 就是 `ELK` 中的 `L`。它是 Elastic Stack 的核心产品之一，可用来对数据进行聚合和处理，并将数据发送到 Elasticsearch。Logstash 是一个开源的服务器端数据处理管道，允许您在将数据索引到 Elasticsearch 之前同时从多个来源采集数据，并对数据进行充实和转换。

`Kibana` 就是 `ELK` 中的  `K`。 是一款适用于 Elasticsearch 的[数据可视化](https://cloud.tencent.com/product/yuntu?from=10680)和管理工具，可以提供实时的直方图、线性图等。

## 关系型和 NoSQL 怎么选？

关系型和NoSQL数据库的选型，考虑几个指标，数据量、并发量、实时性、一致性要求、读写分离、安全性、运维性等。根据这些指标，软件系统可分成几类。

- 管理型系统，如运营类系统，首选关系型。

- **大流量系统**,且多字段、数据量增长快，首选 NoSQL。
- **日志型系统**，首选 Elasticsearch
- **搜索型系统**，指站内搜索，非通用搜索，如商品搜索，首选 Elasticsearch。
- **事务型系统**，如库存、交易、记账，选关系型+缓存+一致性协议。
- **离线计算**，如大量数据分析，首选列式数据库。
- **实时计算**，如实时监控，可以选时序数据库，或列式数据库。



时间序列数据库(Time Series Database)

是用于存储和管理时间序列数据的专业化数据库，具备写多读少、冷热分明、高并发写入、无事务要求、海量数据持续写入等特点，可以基于时间区间聚合分析和高效检索，广泛应用在物联网、经济金融、环境监控、工业制造、农业生产、硬件和软件系统监控等场景。

### InfluxDB



=======================

three-high-import 高可用、高可靠、高性能 三高多线程导入系统 理论贯通

本项目可以在千万级别数据实现无差别高性能数据上报、导入

与普通导入相比性能提高10倍左右

在偶尔的机器宕机、网络波动等情况出现，仍能实现数据一致、数据可靠、数据重、数据报警等功能

在一些重要的数据，例如：对账，账户金额，账单等，需要每日定时任务

而且有高风险的数据实现数据无错误

多线程从基础到进阶，

